# Program to train a model to recognise the handwritten digits
# 55000 images for training, each is a 28*28 image which is flattened into 1D array of size 784.
# Flattening the images discards the 2D information in the image, which we will correct in later algorithms.
# The model is a layer of neurons whih takes the pixel values as input and outputs the probabilities for each of the classes
# A softmax function is used to convert the evidence values generated by matmul(x,W) into probabilities.
# Cross Entropy is the loss function used

import tensorflow as tf

# Read in the input data
from tensorflow.examples.tutorials.mnist import input_data
mnist = input_data.read_data_sets("MNIST_data/", one_hot=True);

# mnist now contains 55000 training images already flattened into arrays, along with the correct labels

# numpy is the python library for numerical computing, the expensive matrix operations are done outside python using
# highly efficient code written in some other language. Even then, switching back to python after every statement can be 
# super expensive. So, tensorflow goes a step further and the computations are desribed as a dataflow graph that runs 
# completely outside python.

# Placeholder for the input images, a placeholder is a value which an be provided as an input while running the graph
x = tf.placeholder(tf.float32, [None, 784])
W = tf.Variable(tf.zeros([784,10])) #W is a rank 2 tensor with shape [784, 10]
b = tf.Variable(tf.zeros([10])) #b is a rank 1 tensor with shape [10], note that there is no need to distinguish between a row vector or a column vector

# Define the model for computing the predited value
yp = tf.nn.softmax(tf.matmul(x,W) + b)

# ----------------------------------------------------------------------------------------------------------------------------
# Training the model

# Expected value or input label
ye = tf.placeholder(tf.float32, [None, 10])

# Cross Entropy Loss : mean of -sumof(ye*log(yp))
cross_entropy = tf.reduce_mean(-tf.reduce_sum(ye*tf.log(yp), reduction_indices=1))

# Backpropagation and optimizer
train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)

# Initialize the variables before running the model
init_var = tf.global_variables_initializer()
sess = tf.InteractiveSession()
sess.run(init_var)

# Run 1000 training steps in batches of 100 randomly seleted input images i.e stochastic gradient descent since computing the mean across all the training examples 
# would take way too much time!

for i in range(1000):
    batch_x, batch_ye = mnist.train.next_batch(100)
    # Make sure to run the entire graph with the batched input rather than the full input.
    sess.run(train_step, {x:batch_x, ye:batch_ye})

# Executing train_step trains the model using stochastic gradient desent

# ----------------------------------------------------------------------------------------------------------------------------
# Evaluation

# argmax returns the index of the largest value in the array which also doubles up as the classification
correct_prediction = tf.equal(tf.argmax(ye,1), tf.argmax(yp,1))
accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))
print(sess.run(accuracy, {x:mnist.test.images, ye:mnist.test.labels}))


